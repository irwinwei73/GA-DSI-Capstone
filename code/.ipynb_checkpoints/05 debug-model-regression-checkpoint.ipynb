{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:06:14.715498Z",
     "start_time": "2019-12-02T04:06:11.022777Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "df = pd.read_csv('../data/df_model_trimmed.csv')\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:06:21.460337Z",
     "start_time": "2019-12-02T04:06:21.416360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>company</th>\n",
       "      <th>auwgr</th>\n",
       "      <th>lkpp</th>\n",
       "      <th>hlr_lag1</th>\n",
       "      <th>hlr_lag2</th>\n",
       "      <th>hlr_lag3</th>\n",
       "      <th>hlr_lag4</th>\n",
       "      <th>hlr_lag5</th>\n",
       "      <th>mer</th>\n",
       "      <th>...</th>\n",
       "      <th>class_fire</th>\n",
       "      <th>class_health</th>\n",
       "      <th>class_mac</th>\n",
       "      <th>class_mahl</th>\n",
       "      <th>class_motor</th>\n",
       "      <th>class_others</th>\n",
       "      <th>class_pa</th>\n",
       "      <th>class_prof_indm</th>\n",
       "      <th>class_pub_lia</th>\n",
       "      <th>class_wic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>c166</td>\n",
       "      <td>1.403847</td>\n",
       "      <td>9.746642</td>\n",
       "      <td>-0.653108</td>\n",
       "      <td>-0.67628</td>\n",
       "      <td>-0.702346</td>\n",
       "      <td>-0.71422</td>\n",
       "      <td>-0.734678</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>c166</td>\n",
       "      <td>1.897721</td>\n",
       "      <td>4.531747</td>\n",
       "      <td>-0.950801</td>\n",
       "      <td>-0.67628</td>\n",
       "      <td>-0.702346</td>\n",
       "      <td>-0.71422</td>\n",
       "      <td>-0.734678</td>\n",
       "      <td>-0.334269</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year company     auwgr      lkpp  hlr_lag1  hlr_lag2  hlr_lag3  hlr_lag4  \\\n",
       "0  2005    c166  1.403847  9.746642 -0.653108  -0.67628 -0.702346  -0.71422   \n",
       "1  2006    c166  1.897721  4.531747 -0.950801  -0.67628 -0.702346  -0.71422   \n",
       "\n",
       "   hlr_lag5       mer  ...  class_fire  class_health  class_mac  class_mahl  \\\n",
       "0 -0.734678 -0.295015  ...           0             0          0           0   \n",
       "1 -0.734678 -0.334269  ...           0             0          0           0   \n",
       "\n",
       "   class_motor  class_others  class_pa  class_prof_indm  class_pub_lia  \\\n",
       "0            0             0         1                0              0   \n",
       "1            0             0         1                0              0   \n",
       "\n",
       "   class_wic  \n",
       "0          0  \n",
       "1          0  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:06:37.113669Z",
     "start_time": "2019-12-02T04:06:37.107674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4347, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:07:58.569322Z",
     "start_time": "2019-12-02T04:07:58.554332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4347, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # drop the 'class' dummies\n",
    "droplist = ['class_bonds','class_cnstr_engr','class_cpr','class_fire','class_health',\n",
    "            'class_mac','class_mahl','class_motor','class_others','class_pa',\n",
    "            'class_prof_indm','class_pub_lia','class_wic']\n",
    "df.drop(columns=droplist,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get features from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:08:04.295308Z",
     "start_time": "2019-12-02T04:08:04.287318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4347, 20)\n",
      "['lkpp', 'hlr_lag1', 'hlr_lag2', 'hlr_lag3', 'hlr_lag4', 'hlr_lag5', 'mer', 'der', 'oer', 'prem_write_net_lag1', 'claim_set_net_lag1', 'exp_management_lag1', 'exp_comm_incur_net_lag1', 'exp_other_lag1', 'prem_liab_diff_lag1', 'claim_liab_diff_lag1', 'uw_gain_lag1']\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "features = [col for col in df._get_numeric_data().columns if (col != 'auwgr') and (col != 'year')]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:08:06.960861Z",
     "start_time": "2019-12-02T04:08:06.946871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:08:09.219870Z",
     "start_time": "2019-12-02T04:08:09.209879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4347, 17)\n",
      "(4347,)\n"
     ]
    }
   ],
   "source": [
    "X = df[features]\n",
    "y = df['auwgr']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T05:32:43.232201Z",
     "start_time": "2019-12-02T05:32:43.216208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3260, 17) (1087, 17)\n",
      "(3260,) (1087,)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T05:32:46.222402Z",
     "start_time": "2019-12-02T05:32:46.207408Z"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear, Ridge, Lasso (with standard scaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T05:32:48.971880Z",
     "start_time": "2019-12-02T05:32:47.943514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LINEAR REG cross-val mean score:\n",
      "X-Val score MEAN using X_train\t\t 0.11119262833850345\n",
      "\n",
      "RIDGE cross-val mean score:\n",
      "X-Val score MEAN using X_train\t\t 0.11351653946765368\n",
      "\n",
      "LASSO cross-val mean score:\n",
      "X-Val score MEAN using X_train\t\t 0.1131184168029213\n"
     ]
    }
   ],
   "source": [
    "# LINEAR REG - Instantiate and score using cross validation (3 folds)\n",
    "linreg = LinearRegression()\n",
    "print('\\nLINEAR REG cross-val mean score:')\n",
    "print('X-Val score MEAN using X_train\\t\\t',cross_val_score(linreg, X_train_sc, y_train,cv=3).mean())\n",
    "\n",
    "# RIDGE - Instantiate and score using cross validation (3 folds)\n",
    "ridge=RidgeCV(alphas=np.linspace(.1, 10, 100))\n",
    "print('\\nRIDGE cross-val mean score:')\n",
    "print('X-Val score MEAN using X_train\\t\\t',cross_val_score(ridge, X_train_sc, y_train,cv=3).mean())\n",
    "\n",
    "# LASSO - Instantiate and score using cross validation (3 folds)\n",
    "lasso = LassoCV(n_alphas=200,cv=3)\n",
    "print('\\nLASSO cross-val mean score:')\n",
    "print('X-Val score MEAN using X_train\\t\\t',cross_val_score(lasso, X_train_sc, y_train,cv=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:08:30.251861Z",
     "start_time": "2019-12-02T04:08:30.013995Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_x = PowerTransformer() # transform X\n",
    "pt_x.fit(X_train)\n",
    "X_train_pt = pt_x.transform(X_train)\n",
    "X_test_pt = pt_x.transform(X_test)\n",
    "\n",
    "pt_y = PowerTransformer() # transform Y\n",
    "# PowerTransformer requires a matrix/DataFrame, so we use .to_frame() method on y_train\n",
    "# subsequently we use .ravel() to flatten it into an array (which is required for cross_val later)\n",
    "pt_y.fit(y_train.to_frame())\n",
    "y_train_pt = pt_y.transform(y_train.to_frame()).ravel()\n",
    "y_test_pt = pt_y.transform(y_test.to_frame()).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear, Ridge Lasso (with power transformed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:08:33.288580Z",
     "start_time": "2019-12-02T04:08:32.183265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LINEAR REG cross-val mean score:\n",
      "X-Val score MEAN using X_train\t\t 0.08187312635603868\n",
      "\n",
      "RIDGE cross-val mean score:\n",
      "X-Val score MEAN using X_train\t\t 0.08303968253782978\n",
      "\n",
      "LASSO cross-val mean score:\n",
      "X-Val score MEAN using X_train\t\t 0.08247678166047641\n"
     ]
    }
   ],
   "source": [
    "# LINEAR REG - Instantiate and score using cross validation (3 folds)\n",
    "linreg = LinearRegression()\n",
    "print('\\nLINEAR REG cross-val mean score:')\n",
    "print('X-Val score MEAN using X_train\\t\\t',cross_val_score(linreg, X_train_pt, y_train_pt,cv=3).mean())\n",
    "\n",
    "# RIDGE - Instantiate and score using cross validation (3 folds)\n",
    "ridge=RidgeCV(alphas=np.linspace(.1, 10, 100))\n",
    "print('\\nRIDGE cross-val mean score:')\n",
    "print('X-Val score MEAN using X_train\\t\\t',cross_val_score(ridge, X_train_pt, y_train_pt,cv=3).mean())\n",
    "\n",
    "# LASSO - Instantiate and score using cross validation (3 folds)\n",
    "lasso = LassoCV(n_alphas=200,cv=3)\n",
    "print('\\nLASSO cross-val mean score:')\n",
    "print('X-Val score MEAN using X_train\\t\\t',cross_val_score(lasso, X_train_pt, y_train_pt,cv=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:08:45.049735Z",
     "start_time": "2019-12-02T04:08:44.917816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999999490874\n",
      "-0.7812532255355314\n"
     ]
    }
   ],
   "source": [
    "dtreg = DecisionTreeRegressor()\n",
    "dtreg.fit(X_train_sc,y_train) # Use un-scaled data\n",
    "# Evaluate model.\n",
    "print(dtreg.score(X_train_sc,y_train))\n",
    "print(dtreg.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:35:28.992455Z",
     "start_time": "2019-11-30T13:35:28.987458Z"
    }
   },
   "outputs": [],
   "source": [
    "# param_grid = [{'max_depth':range(2,1000),\n",
    "#                'min_samples_split':range(2,21)\n",
    "#               }]\n",
    "# reg = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5)\n",
    "# reg.fit(X_train, y_train)\n",
    "# reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:35:29.022436Z",
     "start_time": "2019-11-30T13:35:28.996452Z"
    }
   },
   "outputs": [],
   "source": [
    "# dtreg = DecisionTreeRegressor(max_depth=2, min_samples_split=15)\n",
    "# dtreg.fit(X_train,y_train) # Use un-scaled data\n",
    "# # Evaluate model.\n",
    "# print(dtreg.score(X_train,y_train))\n",
    "# print(dtreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:08:54.989677Z",
     "start_time": "2019-12-02T04:08:54.372063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81783645478352\n",
      "-0.016826547420873972\n"
     ]
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_estimators=10) # default no. of trees ('n_estimators') = 10\n",
    "rfreg.fit(X_train_sc,y_train) # Use un-scaled data\n",
    "# Evaluate model\n",
    "print(rfreg.score(X_train_sc,y_train))\n",
    "print(rfreg.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:35:29.819947Z",
     "start_time": "2019-11-30T13:35:29.814950Z"
    }
   },
   "outputs": [],
   "source": [
    "# param_grid = [{'n_estimators':[50,100,200],\n",
    "#                'max_depth':range(2,50),\n",
    "#                'min_samples_split':range(2,20),\n",
    "#                'oob_score':[True]\n",
    "#               }]\n",
    "# reg = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "# reg.fit(X_train, y_train)\n",
    "# reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:35:29.831941Z",
     "start_time": "2019-11-30T13:35:29.823944Z"
    }
   },
   "outputs": [],
   "source": [
    "# rfreg = RandomForestRegressor(n_estimators=100,max_depth=2,min_samples_split=10,oob_score=True)\n",
    "# rfreg.fit(X_train,y_train) # Use un-scaled data\n",
    "# # Evaluate model\n",
    "# print(rfreg.score(X_train,y_train))\n",
    "# print(rfreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:09:04.186128Z",
     "start_time": "2019-12-02T04:09:02.432212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8785319032217249\n",
      "0.09059870568796191\n"
     ]
    }
   ],
   "source": [
    "etreg = ExtraTreesRegressor(bootstrap=True,oob_score=True,warm_start=False,n_estimators=100)\n",
    "etreg.fit(X_train_sc,y_train) # Use un-scaled data\n",
    "# Evaluate model\n",
    "print(etreg.score(X_train_sc,y_train))\n",
    "print(etreg.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:35:31.926656Z",
     "start_time": "2019-11-30T13:35:31.919662Z"
    }
   },
   "outputs": [],
   "source": [
    "# param_grid = [{'n_estimators':[100,200,300],\n",
    "#                'max_depth':range(2,50),\n",
    "#                'min_samples_split':range(2,20),\n",
    "#                'oob_score':[True],\n",
    "#                'bootstrap':[True]\n",
    "#               }]\n",
    "\n",
    "# reg = GridSearchCV(ExtraTreesRegressor(), param_grid, cv=5)\n",
    "# reg.fit(X_train, y_train)\n",
    "# reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:35:31.936650Z",
     "start_time": "2019-11-30T13:35:31.930653Z"
    }
   },
   "outputs": [],
   "source": [
    "# etreg = ExtraTreesRegressor(bootstrap=True,max_depth=23,min_samples_split=14,n_estimators=100,oob_score=True)\n",
    "# etreg.fit(X_train,y_train) # Use un-scaled data\n",
    "# # Evaluate model\n",
    "# print(etreg.score(X_train,y_train))\n",
    "# print(etreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV (on Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE BELOW (Superseded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additive Feature Search (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T03:52:52.619942Z",
     "start_time": "2019-12-01T03:51:38.889117Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_sc, X_train_pt\n",
    "# X_test_sc, X_test_pt\n",
    "# y_train, y_test\n",
    "\n",
    "# FURTHER TO DO:\n",
    "# select best scoring set of features ==> \n",
    "# send to grid search (dt, rf, et), also send to adaBoost, GradientBoost regressors\n",
    "\n",
    "print('total no. of features to search:',len(features))\n",
    "\n",
    "df_search_results = pd.DataFrame(data=[['','','','','','','','','','','','','','']], \n",
    "                                 index=None, \n",
    "                                 columns=['num_features','list_features','sc_score_linreg','sc_score_ridge',\n",
    "                                          'sc_score_lasso','sc_score_dt','sc_score_rf','sc_score_et',\n",
    "                                          'pt_score_linreg','pt_score_ridge','pt_score_lasso',\n",
    "                                          'pt_score_dt','pt_score_rf','pt_score_et'])\n",
    "\n",
    "df_search_row = pd.DataFrame(data=[['','','','','','','','','','','','','','']], \n",
    "                                 index=None, \n",
    "                                 columns=['num_features','list_features','sc_score_linreg','sc_score_ridge',\n",
    "                                          'sc_score_lasso','sc_score_dt','sc_score_rf','sc_score_et',\n",
    "                                          'pt_score_linreg','pt_score_ridge','pt_score_lasso',\n",
    "                                          'pt_score_dt','pt_score_rf','pt_score_et'])\n",
    "\n",
    "print('Initialization:')\n",
    "display(df_search_row.head(1))\n",
    "\n",
    "feature_searchlist = []\n",
    "y = df['auwgr']\n",
    "\n",
    "for i in features:   \n",
    "    feature_searchlist.append(i)  \n",
    "    print('\\n#########',len(feature_searchlist),'features\\n',feature_searchlist)\n",
    "    X = df[feature_searchlist]\n",
    "    print('X:',X.shape,'y:',y.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_sc = ss.transform(X_train)\n",
    "    X_test_sc = ss.transform(X_test)\n",
    "    pt_x = PowerTransformer() # transform X\n",
    "    pt_x.fit(X_train)\n",
    "    X_train_pt = pt_x.transform(X_train)\n",
    "    X_test_pt = pt_x.transform(X_test)\n",
    "    pt_y = PowerTransformer() # transform Y\n",
    "    pt_y.fit(y_train.to_frame())\n",
    "    y_train_pt = pt_y.transform(y_train.to_frame()).ravel()\n",
    "    y_test_pt = pt_y.transform(y_test.to_frame()).ravel()\n",
    "    \n",
    "    ######################\n",
    "#     print('X (scaled):')\n",
    "\n",
    "    df_search_row['num_features'] = len(feature_searchlist)\n",
    "    df_search_row['list_features'] = str(feature_searchlist)\n",
    "    \n",
    "    df_search_row.loc[0,'sc_score_linreg'] = cross_val_score(LinearRegression(), X_train_sc, y_train,cv=3).mean()\n",
    "    df_search_row.loc[0,'sc_score_ridge'] = cross_val_score(RidgeCV(alphas=np.linspace(.1, 10, 100)), X_train_sc, y_train,cv=3).mean()\n",
    "    df_search_row.loc[0,'sc_score_lasso'] = cross_val_score(LassoCV(n_alphas=200,cv=3), X_train_sc, y_train,cv=3).mean()\n",
    "\n",
    "    dtreg = DecisionTreeRegressor()\n",
    "    dtreg.fit(X_train_sc,y_train)\n",
    "    df_search_row.loc[0,'sc_score_dt'] = dtreg.score(X_test_sc,y_test)\n",
    "    \n",
    "    rfreg = RandomForestRegressor(n_estimators=10)\n",
    "    rfreg.fit(X_train_sc,y_train)\n",
    "    df_search_row.loc[0,'sc_score_rf'] = rfreg.score(X_test_sc,y_test)\n",
    "\n",
    "    etreg = ExtraTreesRegressor(bootstrap=True,oob_score=True,warm_start=False,n_estimators=100)\n",
    "    etreg.fit(X_train_sc,y_train)\n",
    "    df_search_row.loc[0,'sc_score_et'] = etreg.score(X_test_sc,y_test)\n",
    "    \n",
    "    ######################\n",
    "#     print('X (power transformed):')\n",
    "    \n",
    "    df_search_row.loc[0,'pt_score_linreg'] = cross_val_score(LinearRegression(), X_train_pt, y_train_pt,cv=3).mean()\n",
    "    df_search_row.loc[0,'pt_score_ridge'] = cross_val_score(RidgeCV(alphas=np.linspace(.1, 10, 100)), X_train_pt, y_train_pt,cv=3).mean()\n",
    "    df_search_row.loc[0,'pt_score_lasso'] = cross_val_score(LassoCV(n_alphas=200,cv=3), X_train_pt, y_train_pt,cv=3).mean()\n",
    "\n",
    "    dtreg = DecisionTreeRegressor()\n",
    "    dtreg.fit(X_train_pt,y_train_pt)\n",
    "    df_search_row.loc[0,'pt_score_dt'] = dtreg.score(X_test_pt,y_test_pt)\n",
    "\n",
    "    rfreg = RandomForestRegressor(n_estimators=10)\n",
    "    rfreg.fit(X_train_pt,y_train_pt)\n",
    "    df_search_row.loc[0,'pt_score_rf'] = rfreg.score(X_test_pt,y_test_pt)\n",
    "\n",
    "    etreg = ExtraTreesRegressor(bootstrap=True,oob_score=True,warm_start=False,n_estimators=100)\n",
    "    etreg.fit(X_train_pt,y_train_pt)\n",
    "    df_search_row.loc[0,'pt_score_et'] = etreg.score(X_test_pt,y_test_pt)\n",
    "    \n",
    "    ######################\n",
    "    #debug\n",
    "    print('end of iteration:')\n",
    "    print(df_search_row.head(1))\n",
    "    print('append to df_search_results...')\n",
    "    df_search_results = df_search_results.append(df_search_row)\n",
    "    print('shape of df_search_results:',df_search_results.shape)\n",
    "\n",
    "## End of FOR loop\n",
    "print('END of FOR loop')\n",
    "df_search_results.reset_index(drop=True,inplace=True)\n",
    "df_search_results.drop(labels=0,inplace=True)\n",
    "df_search_results.reset_index(drop=True,inplace=True)\n",
    "print(df_search_results.shape)\n",
    "df_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T03:52:59.841125Z",
     "start_time": "2019-12-01T03:52:59.755176Z"
    }
   },
   "outputs": [],
   "source": [
    "df_search_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T03:57:44.282643Z",
     "start_time": "2019-12-01T03:57:44.265656Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_search_results['sc_score_linreg'].max())\n",
    "print(df_search_results['sc_score_ridge'].max())\n",
    "print(df_search_results['sc_score_lasso'].max())\n",
    "print(df_search_results['pt_score_linreg'].max())\n",
    "print(df_search_results['pt_score_ridge'].max())\n",
    "print(df_search_results['pt_score_lasso'].max())\n",
    "print(df_search_results['sc_score_dt'].max())\n",
    "print(df_search_results['sc_score_rf'].max())\n",
    "print(df_search_results['sc_score_et'].max())\n",
    "print(df_search_results['pt_score_dt'].max())\n",
    "print(df_search_results['pt_score_rf'].max())\n",
    "print(df_search_results['pt_score_et'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===> Best score is 0.13626810317016735 ===> Scaled X, Extra Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additive Feature Search (Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T06:21:40.972631Z",
     "start_time": "2019-12-01T06:21:40.965636Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#debug\n",
    "# need to launch notebook using:\n",
    "# \"jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000\"\n",
    "\n",
    "# for num_of_features in range(1,len(features)+1): # this throws an IO error.... \n",
    "\n",
    "for num_of_features in range(1,int(len(features)/5)): # try this first ..from 1 to 7\n",
    "    feature_combo_list = list(itertools.combinations(features,r=num_of_features))\n",
    "    print(feature_combo_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T06:21:44.510826Z",
     "start_time": "2019-12-01T06:21:44.505829Z"
    }
   },
   "outputs": [],
   "source": [
    "len(feature_combo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T06:22:02.912194Z",
     "start_time": "2019-12-01T06:22:02.906197Z"
    }
   },
   "outputs": [],
   "source": [
    "list(feature_combo_list[110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T06:59:28.576466Z",
     "start_time": "2019-12-01T06:29:27.531923Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_sc, X_train_pt\n",
    "# X_test_sc, X_test_pt\n",
    "# y_train, y_test\n",
    "\n",
    "df_search_results = pd.DataFrame(data=[['','','','','','','','','','','','','','']], \n",
    "                                 index=None, \n",
    "                                 columns=['num_features','list_features','sc_score_linreg','sc_score_ridge',\n",
    "                                          'sc_score_lasso','sc_score_dt','sc_score_rf','sc_score_et',\n",
    "                                          'pt_score_linreg','pt_score_ridge','pt_score_lasso',\n",
    "                                          'pt_score_dt','pt_score_rf','pt_score_et'])\n",
    "df_search_row = pd.DataFrame(data=[['','','','','','','','','','','','','','']], \n",
    "                                 index=None, \n",
    "                                 columns=['num_features','list_features','sc_score_linreg','sc_score_ridge',\n",
    "                                          'sc_score_lasso','sc_score_dt','sc_score_rf','sc_score_et',\n",
    "                                          'pt_score_linreg','pt_score_ridge','pt_score_lasso',\n",
    "                                          'pt_score_dt','pt_score_rf','pt_score_et'])\n",
    "y = df['auwgr']\n",
    "\n",
    "# =====\n",
    "\n",
    "for num_of_features in range(1,len(features)+1):\n",
    "    \n",
    "    # generate a list of tuples\n",
    "    feature_combo_list = list(itertools.combinations(features,r=num_of_features))\n",
    "    \n",
    "    # extract each specific tuple of features to search\n",
    "    for specific_list_of_features in feature_combo_list:\n",
    "        \n",
    "        # convert the tuple into a list\n",
    "        specific_list_of_features = list(specific_list_of_features)\n",
    "        X = df[specific_list_of_features]\n",
    "        print('total no. of features to search:',len(specific_list_of_features))\n",
    "        \n",
    "        print('X:',X.shape,'y:',y.shape)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_train)\n",
    "        X_train_sc = ss.transform(X_train)\n",
    "        X_test_sc = ss.transform(X_test)\n",
    "        pt_x = PowerTransformer() # transform X\n",
    "        pt_x.fit(X_train)\n",
    "        X_train_pt = pt_x.transform(X_train)\n",
    "        X_test_pt = pt_x.transform(X_test)\n",
    "        pt_y = PowerTransformer() # transform Y\n",
    "        pt_y.fit(y_train.to_frame())\n",
    "        y_train_pt = pt_y.transform(y_train.to_frame()).ravel()\n",
    "        y_test_pt = pt_y.transform(y_test.to_frame()).ravel()\n",
    "    \n",
    "        ######################\n",
    "        #     print('X (scaled):')\n",
    "        df_search_row['num_features'] = len(specific_list_of_features)\n",
    "        df_search_row['list_features'] = str(specific_list_of_features)\n",
    "        df_search_row.loc[0,'sc_score_linreg'] = cross_val_score(LinearRegression(), X_train_sc, y_train,cv=3).mean()\n",
    "        df_search_row.loc[0,'sc_score_ridge'] = cross_val_score(RidgeCV(alphas=np.linspace(.1, 10, 100)), X_train_sc, y_train,cv=3).mean()\n",
    "        df_search_row.loc[0,'sc_score_lasso'] = cross_val_score(LassoCV(n_alphas=200,cv=3), X_train_sc, y_train,cv=3).mean()\n",
    "        dtreg = DecisionTreeRegressor()\n",
    "        dtreg.fit(X_train_sc,y_train)\n",
    "        df_search_row.loc[0,'sc_score_dt'] = dtreg.score(X_test_sc,y_test)    \n",
    "        rfreg = RandomForestRegressor(n_estimators=10)\n",
    "        rfreg.fit(X_train_sc,y_train)\n",
    "        df_search_row.loc[0,'sc_score_rf'] = rfreg.score(X_test_sc,y_test)\n",
    "        etreg = ExtraTreesRegressor(bootstrap=True,oob_score=True,warm_start=False,n_estimators=100)\n",
    "        etreg.fit(X_train_sc,y_train)\n",
    "        df_search_row.loc[0,'sc_score_et'] = etreg.score(X_test_sc,y_test)\n",
    "        ######################\n",
    "        #     print('X (power transformed):')\n",
    "        df_search_row.loc[0,'pt_score_linreg'] = cross_val_score(LinearRegression(), X_train_pt, y_train_pt,cv=3).mean()\n",
    "        df_search_row.loc[0,'pt_score_ridge'] = cross_val_score(RidgeCV(alphas=np.linspace(.1, 10, 100)), X_train_pt, y_train_pt,cv=3).mean()\n",
    "        df_search_row.loc[0,'pt_score_lasso'] = cross_val_score(LassoCV(n_alphas=200,cv=3), X_train_pt, y_train_pt,cv=3).mean()\n",
    "        dtreg = DecisionTreeRegressor()\n",
    "        dtreg.fit(X_train_pt,y_train_pt)\n",
    "        df_search_row.loc[0,'pt_score_dt'] = dtreg.score(X_test_pt,y_test_pt)\n",
    "        rfreg = RandomForestRegressor(n_estimators=10)\n",
    "        rfreg.fit(X_train_pt,y_train_pt)\n",
    "        df_search_row.loc[0,'pt_score_rf'] = rfreg.score(X_test_pt,y_test_pt)\n",
    "        etreg = ExtraTreesRegressor(bootstrap=True,oob_score=True,warm_start=False,n_estimators=100)\n",
    "        etreg.fit(X_train_pt,y_train_pt)\n",
    "        df_search_row.loc[0,'pt_score_et'] = etreg.score(X_test_pt,y_test_pt)\n",
    "        ######################\n",
    "        #debug\n",
    "        df_search_results = df_search_results.append(df_search_row)\n",
    "        print('shape of df_search_results:',df_search_results.shape)\n",
    "\n",
    "    ## End of INNER FOR loop\n",
    "    print('end of INNER FOR loop:',df_search_results.shape)\n",
    "\n",
    "# End of OUTER FOR Loop\n",
    "df_search_results.reset_index(drop=True,inplace=True)\n",
    "df_search_results.drop(labels=0,inplace=True)\n",
    "df_search_results.reset_index(drop=True,inplace=True)\n",
    "print(df_search_results.shape)\n",
    "df_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T06:59:34.821331Z",
     "start_time": "2019-12-01T06:59:34.797347Z"
    }
   },
   "outputs": [],
   "source": [
    "df_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T06:59:39.435968Z",
     "start_time": "2019-12-01T06:59:39.225100Z"
    }
   },
   "outputs": [],
   "source": [
    "df_search_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T07:05:56.862312Z",
     "start_time": "2019-12-01T07:05:56.821341Z"
    }
   },
   "outputs": [],
   "source": [
    "df_search_results.reset_index(drop=True,inplace=True)\n",
    "df_search_results.drop(labels=0,inplace=True)\n",
    "df_search_results.reset_index(drop=True,inplace=True)\n",
    "print(df_search_results.shape)\n",
    "df_search_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T07:06:09.509769Z",
     "start_time": "2019-12-01T07:06:09.488788Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_search_results['sc_score_linreg'].max())\n",
    "print(df_search_results['sc_score_ridge'].max())\n",
    "print(df_search_results['sc_score_lasso'].max())\n",
    "print(df_search_results['pt_score_linreg'].max())\n",
    "print(df_search_results['pt_score_ridge'].max())\n",
    "print(df_search_results['pt_score_lasso'].max())\n",
    "print(df_search_results['sc_score_dt'].max())\n",
    "print(df_search_results['sc_score_rf'].max())\n",
    "print(df_search_results['sc_score_et'].max())\n",
    "print(df_search_results['pt_score_dt'].max())\n",
    "print(df_search_results['pt_score_rf'].max())\n",
    "print(df_search_results['pt_score_et'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T05:45:50.839432Z",
     "start_time": "2019-12-01T05:45:50.835436Z"
    }
   },
   "outputs": [],
   "source": [
    "# FURTHER TO DO:\n",
    "# select best scoring set of features ==> \n",
    "# send to grid search (dt, rf, et), also send to adaBoost, GradientBoost regressors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 390,
   "position": {
    "height": "40px",
    "left": "658px",
    "right": "20px",
    "top": "8px",
    "width": "580px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
